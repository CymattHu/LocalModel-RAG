import torch
import onnx
import traceback
import gradio as gr
from io import BytesIO
import zipfile
import tarfile

def load_model_from_bytes(file_bytes, filename):
    ext = filename.lower()
    file_bytes.seek(0)
    data = file_bytes.read()

    if ext.endswith(".safetensors"):
        try:
            from safetensors.torch import load_file
        except ImportError:
            return None, "âŒ æœªå®‰è£… safetensors åº“ï¼Œè¯·å…ˆè¿è¡Œ `pip install safetensors`"

        try:
            # safetensors åŠ è½½ä¸º state_dict
            state_dict = load_file(BytesIO(data))
            return state_dict, None
        except Exception as e:
            return None, f"âŒ safetensors æ–‡ä»¶åŠ è½½å¤±è´¥: {e}"

    # å…¶ä»–æ ¼å¼å¤„ç†
    try:
        return torch.load(BytesIO(data), map_location="cpu"), None
    except Exception as e:
        # å°è¯•è§£å‹ zip
        if ext.endswith(".zip"):
            try:
                with zipfile.ZipFile(BytesIO(data)) as zf:
                    for f in zf.namelist():
                        if f.endswith((".pt", ".pth")):
                            with zf.open(f) as model_file:
                                model_data = model_file.read()
                                return torch.load(BytesIO(model_data), map_location="cpu"), None
                return None, "ZIPåŒ…å†…æœªæ‰¾åˆ° .pt æˆ– .pth æ¨¡å‹æ–‡ä»¶"
            except Exception as e2:
                return None, f"è§£å‹ ZIP å¤±è´¥: {e2}"
        # å°è¯•è§£å‹ tar
        elif ext.endswith(".tar") or ext.endswith(".tar.gz") or ext.endswith(".tgz") or ext.endswith(".pth.tar"):
            try:
                with tarfile.open(fileobj=BytesIO(data)) as tf:
                    for member in tf.getmembers():
                        if member.name.endswith((".pt", ".pth")):
                            f = tf.extractfile(member)
                            if f:
                                model_data = f.read()
                                return torch.load(BytesIO(model_data), map_location="cpu"), None
                return None, "tar åŒ…å†…æœªæ‰¾åˆ° .pt æˆ– .pth æ¨¡å‹æ–‡ä»¶"
            except Exception as e3:
                return None, f"è§£å‹ TAR å¤±è´¥: {e3}"
        else:
            return None, f"ä¸æ”¯æŒçš„æ¨¡å‹æ–‡ä»¶æ ¼å¼æˆ–åŠ è½½å¤±è´¥ï¼š{e}"

def export_to_onnx_from_file(model_file, input_shape_str, simplify=True):
    if model_file is None:
        return "âŒ è¯·ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", None

    try:
        input_shape = tuple(int(x) for x in input_shape_str.strip().split(","))
    except Exception as e:
        return f"âŒ è¾“å…¥å½¢çŠ¶æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºé€—å·åˆ†éš”çš„æ•´æ•°ï¼Œå¦‚ 1,3,224,224ã€‚é”™è¯¯ï¼š{e}", None

    model, err = load_model_from_bytes(model_file, model_file.name)
    if err:
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {err}", None

    # å¦‚æœæ˜¯state_dictï¼Œå°è¯•è‡ªåŠ¨è½½å…¥resnet18
    if isinstance(model, dict):
        try:
            from torchvision.models import resnet18
            base_model = resnet18(pretrained=False)
            base_model.load_state_dict(model)
            model = base_model
        except Exception as e:
            return f"âŒ state_dictåŠ è½½åˆ°æ¨¡å‹å¤±è´¥: {e}", None

    model.eval()
    dummy_input = torch.randn(input_shape)
    export_path = "exported_model.onnx"

    try:
        torch.onnx.export(model, dummy_input, export_path,
                          input_names=["input"],
                          output_names=["output"],
                          dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
                          opset_version=11)
    except Exception as e:
        return f"âŒ ONNX å¯¼å‡ºå¤±è´¥ï¼š{e}\n{traceback.format_exc()}", None

    try:
        model_onnx = onnx.load(export_path)
        onnx.checker.check_model(model_onnx)

        inputs_info = []
        for inp in model_onnx.graph.input:
            shape = [dim.dim_param or dim.dim_value for dim in inp.type.tensor_type.shape.dim]
            inputs_info.append(f"{inp.name}: {shape}")

        outputs_info = []
        for out in model_onnx.graph.output:
            shape = [dim.dim_param or dim.dim_value for dim in out.type.tensor_type.shape.dim]
            outputs_info.append(f"{out.name}: {shape}")

        info_text = (
            f"âœ… æ¨¡å‹æˆåŠŸå¯¼å‡ºä¸º {export_path}\n\n"
            "ğŸ“Œ æ¨¡å‹è¾“å…¥:\n" + "\n".join(inputs_info) + "\n\n"
            "ğŸ“Œ æ¨¡å‹è¾“å‡º:\n" + "\n".join(outputs_info)
        )

    except Exception as e:
        return f"âŒ éªŒè¯ ONNX æ¨¡å‹å¤±è´¥ï¼š{e}", None

    return info_text, export_path


def main():
    with gr.Blocks() as demo:
        gr.Markdown("# PyTorch æ¨¡å‹å¯¼å‡ºä¸º ONNX  ğŸ“¦")
        gr.Markdown(
            "ä¸Šä¼ ä½ çš„ PyTorch æ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒ `.pt`ã€`.pth`ã€`.zip`ã€`.tar`ã€`.pkl`ã€`.safetensors` ç­‰æ ¼å¼ã€‚\n\n"
            "å¹¶è¾“å…¥æ¨¡å‹è¾“å…¥å½¢çŠ¶ï¼ˆé€—å·åˆ†éš”çš„æ•´æ•°ï¼‰ï¼Œ"
            "ä¾‹å¦‚ `1,3,224,224` è¡¨ç¤º batch=1ï¼Œ3 é€šé“ï¼Œ224x224 å¤§å°ã€‚"
        )

        model_file = gr.File(label="ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", file_types=[".pt", ".pth", ".zip", ".tar", ".pkl", ".safetensors", ".tar.gz", ".tgz", ".pth.tar"])
        input_shape = gr.Textbox(label="è¾“å…¥å½¢çŠ¶ (é€—å·åˆ†éš”æ•´æ•°)", value="1,3,224,224")
        output_area = gr.Textbox(label="å¯¼å‡ºçŠ¶æ€ä¸æ¨¡å‹ä¿¡æ¯", interactive=False, lines=10)
        export_button = gr.Button("å¯¼å‡ºä¸º ONNX")

        export_button.click(fn=export_to_onnx_from_file,
                            inputs=[model_file, input_shape],
                            outputs=[output_area, gr.File(label="ä¸‹è½½ ONNX æ¨¡å‹")])

    demo.launch()


if __name__ == "__main__":
    main()
